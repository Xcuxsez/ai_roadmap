ðŸš€ AI Learning Roadmap

This roadmap guides you from the essential foundations of math and Python into the core of classical machine learning, where you learn regression, classification, clustering, and model evaluation. It then progresses into neural networks, starting with simple perceptrons and deep feed-forward models before moving into computer vision with CNNs, sequence modeling with RNNs/LSTMs, and modern Transformers and attention mechanisms. After mastering supervised and unsupervised learning, the roadmap introduces reinforcement learning, followed by advanced subjects like GANs, graph neural networks, and practical projects that solidify each stage. Step by step, it builds your skills from beginner to research-level AI practitioner.
------------------------------------------------------------------------------------------------------------------------------------------------------



ðŸ“˜ Level 0 â€“ Foundations (Math + Python)
Math

â€¢ Linear algebra

â€¢ Calculus

â€¢ Probability and statistics

â€¢ Optimization and gradient descent

Python

â€¢ Python basics

â€¢ Numpy

â€¢ Pandas

â€¢ Matplotlib

â€¢ Jupyter notebooks

â€¢ Git and GitHub basics


------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“™ Level 1 â€“ Classical Machine Learning
Regression

â€¢ Simple linear regression

â€¢ Multiple linear regression

â€¢ Ridge regression

â€¢ Lasso regression and feature selection

â€¢ Gradient descent

â€¢ Stochastic gradient descent

â€¢ Cross-validation

â€¢ Evaluation metrics (MSE, MAE, RÂ²)

â€¢ Scikit-learn

Classification

â€¢ Logistic regression

â€¢ k-Nearest Neighbors (k-NN)

â€¢ Support Vector Machines (SVM)

â€¢ Naive Bayes

â€¢ Decision trees

â€¢ Random forest

â€¢ Gradient boosting (XGBoost, LightGBM)

Unsupervised Learning

â€¢ K-means clustering

â€¢ Spectral clustering

â€¢ Mean shift

â€¢ Hierarchical clustering

â€¢ PCA

â€¢ t-SNE

â€¢ UMAP



------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“— Level 2 â€“ Neural Network Basics

â€¢ Perceptron (single neuron model)

â€¢ Single-layer neural networks

â€¢ Multi-layer perceptrons (MLP)

â€¢ Deep neural networks (DNN)

â€¢ Forward and backward propagation

â€¢ Activation functions (ReLU, Sigmoid, Tanh, Softmax)

â€¢ Loss functions (cross-entropy, MSE)

â€¢ Regularization (Dropout, BatchNorm)

â€¢ Hyperparameter tuning

Frameworks

â€¢ Keras

â€¢ TensorFlow

â€¢ PyTorch

------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“˜ Level 3 â€“ Convolutional Neural Networks (CNNs)

â€¢ Convolutions and feature maps

â€¢ Pooling layers

â€¢ Padding and stride

â€¢ CNN architectures: LeNet, AlexNet, VGG, ResNet, MobileNet, EfficientNet

â€¢ Data augmentation

â€¢ Transfer learning

â€¢ Fine-tuning pretrained models


------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“™ Level 4 â€“ Sequence Models (RNNs & LSTMs)

â€¢ Recurrent neural networks (RNNs)

â€¢ Vanishing and exploding gradients

â€¢ GRU

â€¢ LSTM

â€¢ Bidirectional RNNs

â€¢ Sequence-to-sequence models

â€¢ Teacher forcing

Applications

â€¢ Speech emotion recognition

â€¢ Text classification

â€¢ Named entity recognition

â€¢ Time series forecasting

------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“— Level 5 â€“ Transformers & Attention

â€¢ Attention mechanism

â€¢ Self-attention

â€¢ Multi-head attention

â€¢ Positional encoding

â€¢ Transformer encoderâ€“decoder architecture

â€¢ BERT

â€¢ GPT-style models

â€¢ Vision transformers (ViT)

------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“˜ Level 6 â€“ Reinforcement Learning

â€¢ Markov decision processes (MDP)

â€¢ States, actions, rewards

â€¢ Q-learning

â€¢ SARSA

â€¢ Deep Q-Networks (DQN)

â€¢ Policy gradients

â€¢ Actor-critic methods

â€¢ PPO

â€¢ A3C

------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“™ Level 7 â€“ Advanced Topics
Generative Models

â€¢ Variational autoencoders (VAE)

â€¢ Generative adversarial networks (GANs)

â€¢ DCGAN

â€¢ CycleGAN

â€¢ StyleGAN

â€¢ Diffusion models

Graph Neural Networks

â€¢ Graph convolutional networks (GCN)

â€¢ Graph attention networks (GAT)

â€¢ Node classification

â€¢ Link prediction

â€¢ Graph embeddings

------------------------------------------------------------------------------------------------------------------------------------------------------



ðŸ“š Useful Links and Resources

A curated list of high-quality, official, and reliable resources that support each stage of the roadmap.


------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“˜ Math & Python Foundations
Math for ML

â€¢ Linear Algebra (MIT OpenCourseWare): https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/

â€¢ Calculus (Khan Academy): https://www.khanacademy.org/math/calculus-1

â€¢ Probability & Statistics (Khan Academy): https://www.khanacademy.org/math/statistics-probability

â€¢ Mathematics for Machine Learning (Imperial College London): https://mml-book.github.io/

Python

â€¢ Python Tutorial (Official): https://docs.python.org/3/tutorial/

â€¢ Numpy Documentation: https://numpy.org/doc/

â€¢ Pandas Documentation: https://pandas.pydata.org/docs/

â€¢ Matplotlib Guide: https://matplotlib.org/stable/users/index.html
------------------------------------------------------------------------------------------------------------------------------------------------------



Git

â€¢ Git Book: https://git-scm.com/book/en/v2

------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“™ Classical Machine Learning
Machine Learning Basics

â€¢ Scikit-Learn Documentation: https://scikit-learn.org/stable/

â€¢ Andrew Ng ML Course: https://www.coursera.org/learn/machine-learning

â€¢ Elements of Statistical Learning (Free Book): https://hastie.su.domains/ElemStatLearn/

Algorithms

â€¢ XGBoost Documentation: https://xgboost.readthedocs.io/en/stable/

â€¢ LightGBM Documentation: https://lightgbm.readthedocs.io/

â€¢ CatBoost Documentation: https://catboost.ai/en/docs/


------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“— Neural Network Basics
Deep Learning Foundations

â€¢ Deep Learning Book (Goodfellow et al.): https://www.deeplearningbook.org/

â€¢ Neural Networks Demystified (YouTube Playlist): https://www.youtube.com/playlist?list=PLtBw6njQRUjrsgsFtmM4T6gD3LtZApBjy

Frameworks

â€¢ TensorFlow Documentation: https://www.tensorflow.org/

â€¢ Keras Guide: https://keras.io/

â€¢ PyTorch Documentation: https://pytorch.org/docs/stable/

â€¢ fast.ai Course (Practical DL): https://course.fast.ai

ðŸ“˜ Computer Vision (CNNs)

â€¢ Stanford CS231n â€” Convolutional Neural Networks: https://cs231n.github.io/

â€¢ PyTorch Vision Tutorials: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html

â€¢ Fast.ai Vision Course: https://course.fast.ai


------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“™ Sequence Models (RNNs, LSTMs)

â€¢ Understanding LSTM Networks: https://colah.github.io/posts/2015-08-Understanding-LSTMs/

â€¢ PyTorch RNN Tutorials: https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html

â€¢ Deep Learning Specialization (Sequence Models): https://www.coursera.org/specializations/deep-learning

ðŸ“— Transformers & Attention

â€¢ The Annotated Transformer: http://nlp.seas.harvard.edu/2018/04/03/attention.html

â€¢ Transformers from Scratch (Blog): https://peterbloem.nl/blog/transformers

â€¢ Hugging Face Transformers Course: https://huggingface.co/learn/nlp-course

â€¢ BERT Paper: https://arxiv.org/abs/1810.04805

â€¢ Attention Is All You Need (Original Transformer Paper): https://arxiv.org/abs/1706.03762



------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“˜ Reinforcement Learning

â€¢ Sutton & Barto â€” Reinforcement Learning (Free Book): https://incompleteideas.net/book/the-book.html

â€¢ OpenAI Spinning Up (Practical RL Guide): https://spinningup.openai.com/

â€¢ Gymnasium (OpenAI Gym successor): https://gymnasium.farama.org/



------------------------------------------------------------------------------------------------------------------------------------------------------


ðŸ“™ Advanced Topics
Generative Models

â€¢ GANs Explained: https://deepmind.com/blog/article/gan

â€¢ DCGAN Tutorial (PyTorch): https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html

â€¢ Diffusion Models Overview: https://lilianweng.github.io/posts/2021-07-11-diffusion-models/

Graph Neural Networks

â€¢ Deep Graph Library (DGL): https://www.dgl.ai/

â€¢ PyTorch Geometric (PyG): https://pytorch-geometric.readthedocs.io/en/latest/

â€¢ Stanford CS224W (Graphs & GNNs): http://web.stanford.edu/class/cs224w/

ðŸ›  Tools & Practice

â€¢ Kaggle Competitions: https://www.kaggle.com

â€¢ Papers With Code (SOTA models): https://paperswithcode.com

â€¢ Google Colab: https://colab.research.google.com

â€¢ Weights & Biases (Experiment Tracking): https://wandb.ai

â€¢ VSCode: https://code.visualstudio.com/
